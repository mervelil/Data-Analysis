{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# Modifiers\n",
    "# . = any character\n",
    "# ? = 0 or 1 repetition\n",
    "# + = 1 or more repetition\n",
    "# * = 0 or more repetition\n",
    "# () = group of characters\n",
    "# [] = any of the characters\n",
    "# ^ = starts with\n",
    "# $ = ends with\n",
    "# | = logical or\n",
    "\n",
    "# special characters\n",
    "# \\d matches any digit\n",
    "# \\D matches any not a digit\n",
    "# \\w matches any alphanumeric character\n",
    "# \\W matches any not alphanumeric character\n",
    "# \\s matches any space\n",
    "# \\S matches any not a space\n",
    "# \\t matches any tab\n",
    "# \\n matches any new line\n",
    "\n",
    "# some functions \n",
    "# re.find_all\n",
    "# re.search\n",
    "# re.sub\n",
    "# re.split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2adf261",
   "metadata": {},
   "source": [
    "## Exercise 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from the following links:\n",
    "# https://raw.githubusercontent.com/homsit/files/main/invdata1.txt\n",
    "# https://raw.githubusercontent.com/homsit/files/main/invdata2.txt\n",
    "# verify if there is a duplicate in each file (is there any bacode number that was scanned more than one time)\n",
    "# find shared barcodes in both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff92c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "data1=requests.get('https://raw.githubusercontent.com/homsit/files/main/invdata1.txt').text\n",
    "data2=requests.get('https://raw.githubusercontent.com/homsit/files/main/invdata2.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25cff64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of all barcodes is: 1000\n",
      "The number of munique barcodes is: 986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify if there is a duplicate in file 1\n",
    "print('The number of all barcodes is:',len(data1.split(',')))\n",
    "print('The number of munique barcodes is:',len(set(data1.split(','))))\n",
    "len(data1.split(','))-len(set(data1.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "debb04db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of all barcodes is: 1000\n",
      "The number of munique barcodes is: 987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify if there is a duplicate in file 2\n",
    "print('The number of all barcodes is:',len(data2.split(',')))\n",
    "print('The number of munique barcodes is:',len(set(data2.split(','))))\n",
    "len(data2.split(','))-len(set(data2.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e64b097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'105872287233',\n",
       " '153989350082',\n",
       " '207771969694',\n",
       " '243847654348',\n",
       " '259632295385',\n",
       " '413542186813',\n",
       " '458555138950',\n",
       " '492207218253',\n",
       " '551310033304',\n",
       " '717781672640',\n",
       " '719486334908',\n",
       " '797221317932',\n",
       " '805610984521',\n",
       " '862953114274'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find shared barcodes in both files\n",
    "s1=set(data1.split(','))\n",
    "s2=set(data2.split(','))\n",
    "s1&s2  # shared barcodes\n",
    "s1-s2  # numbers available in data1 not in data2\n",
    "s1|s2  # all unique barcodes in both files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dc4a2",
   "metadata": {},
   "source": [
    "## Scrap the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b4ce04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(list(soup.children)[1].children)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a95124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.get_text()\n",
    "# soup.find_all('h3')\n",
    "# soup.find_all('h3',{'class':'media__title'})[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "121faeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  bs4 import BeautifulSoup\n",
    "response=requests.get('https://www.bbc.com/')\n",
    "soup=BeautifulSoup(response.text)\n",
    "headlines=[l.get_text().strip() for l in soup.find_all('a',{'class':'media__link'})]\n",
    "f=open('bbc-june-16-2022.txt','w')\n",
    "f.write('\\n'.join(headlines))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c9d485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text=' '.join(headlines).lower()\n",
    "for c in string.punctuation:\n",
    "    text=text.replace(c, '')\n",
    "from nltk.corpus import stopwords\n",
    "words=text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2261e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words=[w for w in words if w not in stopwords.words('english')]\n",
    "freq={}\n",
    "for w in clean_words:\n",
    "    if w not in freq:\n",
    "        freq[w]=1\n",
    "    else:\n",
    "        freq[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "47c3ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('climate', 3),\n",
       " ('pictures', 3),\n",
       " ('urged', 2),\n",
       " ('us', 2),\n",
       " ('human', 2),\n",
       " ('betrayed', 2),\n",
       " ('town', 2),\n",
       " ('rise', 2),\n",
       " ('digital', 2),\n",
       " ('could', 2),\n",
       " ('man', 2),\n",
       " ('uses', 2),\n",
       " ('forklift', 2),\n",
       " ('trap', 2),\n",
       " ('wouldbe', 2),\n",
       " ('thief', 2),\n",
       " ('car', 2),\n",
       " ('damage', 2),\n",
       " ('stars', 2),\n",
       " ('jubilee', 2),\n",
       " ('eu', 1),\n",
       " ('leaders', 1),\n",
       " ('kyiv', 1),\n",
       " ('raise', 1),\n",
       " ('pressure', 1),\n",
       " ('russia', 1),\n",
       " ('raid', 1),\n",
       " ('catches', 1),\n",
       " ('senior', 1),\n",
       " ('leader', 1),\n",
       " ('alive', 1),\n",
       " ('syria', 1),\n",
       " ('eight', 1),\n",
       " ('million', 1),\n",
       " ('australians', 1),\n",
       " ('turn', 1),\n",
       " ('lights', 1),\n",
       " ('progress', 1),\n",
       " ('peaked', 1),\n",
       " ('genius', 1),\n",
       " ('composer', 1),\n",
       " ('history', 1),\n",
       " ('amazon', 1),\n",
       " ('suspect', 1),\n",
       " ('leads', 1),\n",
       " ('police', 1),\n",
       " ('remains', 1),\n",
       " ('russians', 1),\n",
       " ('said', 1),\n",
       " ('beatings', 1),\n",
       " ('reeducation', 1),\n",
       " ('kevin', 1),\n",
       " ('spacey', 1),\n",
       " ('bailed', 1),\n",
       " ('sexual', 1),\n",
       " ('assault', 1),\n",
       " ('charges', 1),\n",
       " ('open', 1),\n",
       " ('round', 1),\n",
       " ('one', 1),\n",
       " ('mcilroy', 1),\n",
       " ('rahm', 1),\n",
       " ('make', 1),\n",
       " ('strong', 1),\n",
       " ('starts', 1),\n",
       " ('fixtures', 1),\n",
       " ('announced', 1),\n",
       " ('unique', 1),\n",
       " ('premier', 1),\n",
       " ('league', 1),\n",
       " ('season', 1),\n",
       " ('european', 1),\n",
       " ('football', 1),\n",
       " ('danger', 1),\n",
       " ('says', 1),\n",
       " ('la', 1),\n",
       " ('liga', 1),\n",
       " ('boss', 1),\n",
       " ('uks', 1),\n",
       " ('wacky', 1),\n",
       " ('market', 1),\n",
       " ('nomad', 1),\n",
       " ('families', 1),\n",
       " ('inside', 1),\n",
       " ('kate', 1),\n",
       " ('bushs', 1),\n",
       " ('alternate', 1),\n",
       " ('universe', 1),\n",
       " ('english', 1),\n",
       " ('welcomed', 1),\n",
       " ('dark', 1),\n",
       " ('please', 1),\n",
       " ('ask', 1),\n",
       " ('ambulance', 1),\n",
       " ('hurry', 1),\n",
       " ('ill', 1),\n",
       " ('dead', 1),\n",
       " ('country', 1),\n",
       " ('buy', 1),\n",
       " ('anything', 1),\n",
       " ('bitcoin', 1),\n",
       " ('saudis', 1),\n",
       " ('seize', 1),\n",
       " ('immoral', 1),\n",
       " ('rainbowcoloured', 1),\n",
       " ('toys', 1),\n",
       " ('foods', 1),\n",
       " ('prevent', 1),\n",
       " ('disasters', 1),\n",
       " ('dont', 1),\n",
       " ('treat', 1),\n",
       " ('business', 1),\n",
       " ('like', 1),\n",
       " ('baby', 1),\n",
       " ('storm', 1),\n",
       " ('eunice', 1),\n",
       " ('topples', 1),\n",
       " ('trees', 1),\n",
       " ('rips', 1),\n",
       " ('roofs', 1),\n",
       " ('seagulls', 1),\n",
       " ('beware', 1),\n",
       " ('dogs', 1),\n",
       " ('keeping', 1),\n",
       " ('chips', 1),\n",
       " ('safe', 1),\n",
       " ('wheels', 1),\n",
       " ('wheelchairs', 1),\n",
       " ('team', 1),\n",
       " ('high', 1),\n",
       " ('speed', 1),\n",
       " ('boy', 1),\n",
       " ('rescued', 1),\n",
       " ('100', 1),\n",
       " ('hours', 1),\n",
       " ('trapped', 1),\n",
       " ('well', 1),\n",
       " ('ready', 1),\n",
       " ('total', 1),\n",
       " ('solar', 1),\n",
       " ('eclipse', 1),\n",
       " ('great', 1),\n",
       " ('mosque', 1),\n",
       " ('alnuri', 1),\n",
       " ('destroyed', 1),\n",
       " ('video', 1),\n",
       " ('shows', 1),\n",
       " ('mosul', 1),\n",
       " ('mosques', 1),\n",
       " ('destruction', 1),\n",
       " ('female', 1),\n",
       " ('fitness', 1),\n",
       " ('model', 1),\n",
       " ('burglar', 1),\n",
       " ('caught', 1),\n",
       " ('pants', 1),\n",
       " ('oyster', 1),\n",
       " ('farmers', 1),\n",
       " ('hit', 1),\n",
       " ('change', 1),\n",
       " ('tonnes', 1),\n",
       " ('fruit', 1),\n",
       " ('veg', 1),\n",
       " ('waste', 1),\n",
       " ('saved', 1),\n",
       " ('havent', 1),\n",
       " ('healed', 1),\n",
       " ('grenfell', 1),\n",
       " ('survivor', 1),\n",
       " ('ros', 1),\n",
       " ('atkins', 1),\n",
       " ('on…', 1),\n",
       " ('rwanda', 1),\n",
       " ('asylum', 1),\n",
       " ('seekers', 1),\n",
       " ('hong', 1),\n",
       " ('kongs', 1),\n",
       " ('iconic', 1),\n",
       " ('floating', 1),\n",
       " ('restaurant', 1),\n",
       " ('towed', 1),\n",
       " ('microsoft', 1),\n",
       " ('finally', 1),\n",
       " ('retires', 1),\n",
       " ('internet', 1),\n",
       " ('explorer', 1),\n",
       " ('humanlike', 1),\n",
       " ('sophisticated', 1),\n",
       " ('chatbots', 1),\n",
       " ('new', 1),\n",
       " ('photos', 1),\n",
       " ('show', 1),\n",
       " ('marilyn', 1),\n",
       " ('monroe', 1),\n",
       " ('gown', 1),\n",
       " ('poor', 1),\n",
       " ('nations', 1),\n",
       " ('cash', 1),\n",
       " ('dozens', 1),\n",
       " ('covid', 1),\n",
       " ('cases', 1),\n",
       " ('linked', 1),\n",
       " ('beijing', 1),\n",
       " ('bar', 1),\n",
       " ('anglosaxon', 1),\n",
       " ('burial', 1),\n",
       " ('ground', 1),\n",
       " ('unearthed', 1),\n",
       " ('hs2', 1),\n",
       " ('site', 1),\n",
       " ('megan', 1),\n",
       " ('thee', 1),\n",
       " ('stallion', 1),\n",
       " ('living', 1),\n",
       " ('bullet', 1),\n",
       " ('fragments', 1),\n",
       " ('feet', 1),\n",
       " ('flat', 1),\n",
       " ('tyres', 1),\n",
       " ('soon', 1),\n",
       " ('thing', 1),\n",
       " ('past', 1),\n",
       " ('might', 1),\n",
       " ('twin', 1),\n",
       " ('within', 1),\n",
       " ('decade', 1),\n",
       " ('royal', 1),\n",
       " ('ascot', 1),\n",
       " ('ladies', 1),\n",
       " ('day', 1),\n",
       " ('2022', 1),\n",
       " ('visually', 1),\n",
       " ('impaired', 1),\n",
       " ('artistic', 1),\n",
       " ('africas', 1),\n",
       " ('top', 1),\n",
       " ('shots', 1),\n",
       " ('surfing', 1),\n",
       " ('mellow', 1),\n",
       " ('mermaids', 1),\n",
       " ('platinum', 1),\n",
       " ('pageant', 1),\n",
       " ('throw', 1),\n",
       " ('party', 1)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(freq.items(), key=lambda t:t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa60b5d",
   "metadata": {},
   "source": [
    "## Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "22695c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response=requests.get('https://www.usatoday.com/news/')\n",
    "soup=BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9a574245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class article:\n",
    "    def __init__(self, title, category, author, link):\n",
    "        self.title=title\n",
    "        self.category=category\n",
    "        self.author=author\n",
    "        self.link=link\n",
    "    def __str__(self):\n",
    "        return self.title +','+ self.category+','+self.author+','+self.link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8aaeefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.usatoday.com/news/\n",
      "https://www.usatoday.com/sports/\n",
      "https://www.usatoday.com/entertainment/\n",
      "https://www.usatoday.com/life/\n",
      "https://www.usatoday.com/money/\n"
     ]
    }
   ],
   "source": [
    "main_links=['https://www.usatoday.com'+c['href'] for c in soup.find_all('a',{'class':'gnt_n_mn_l'})]\n",
    "articles=[]\n",
    "for ml in main_links[:5]:\n",
    "    print(ml)\n",
    "    response=requests.get(ml)\n",
    "    soup=BeautifulSoup(response.text)\n",
    "    links=['https://www.usatoday.com'+t['href'] for t in soup.find_all('a',{'class':'gnt_m_th_a'})]\n",
    "    \n",
    "    for l in links:\n",
    "        response=requests.get(l)\n",
    "        soup=BeautifulSoup(response.text)\n",
    "        try:\n",
    "            title=soup.find('h1',{'class':'gnt_ar_hl'}).get_text()\n",
    "        except:\n",
    "            title='None'\n",
    "        try:\n",
    "            category=soup.find('a',{'class':'gnt_ar_lbl_a'}).get_text()\n",
    "        except:\n",
    "            category='None'\n",
    "        try:\n",
    "            author=soup.find('a',{'class':'gnt_ar_by_a'}).get_text()\n",
    "        except:\n",
    "            author='None'\n",
    "        articles.append(article(title,category,author,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fdaaf039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('usatodaynews.dat','wb')\n",
    "pickle.dump(articles,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0e291687",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('usatodaynews.txt','w')\n",
    "for a in articles:\n",
    "    f.write(a.__str__())\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e424c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
